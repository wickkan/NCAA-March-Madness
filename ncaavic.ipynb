{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91497,"databundleVersionId":11320667,"sourceType":"competition"}],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Loading in data","metadata":{}},{"cell_type":"markdown","source":"## Data Section 1 - The Basics\n\n**This section provides everything you need to build a simple prediction model and submit predictions.**\n\n- Team ID's and Team Names\n- Tournament seeds since 1984-85 season\n- Final scores of all regular season, conference tournament, and NCAAÂ® tournament games since 1984-85 season\n- Season-level details including dates and region names\n- Example submission file for stage 1\n  \nBy convention, when we identify a particular season, we will reference the year that the season ends in, not the year that it starts in.\n\n## Data Section 2 - Team Box Scores\n\n**This section provides game-by-game stats at a team level (free throws attempted, defensive rebounds, turnovers, etc.) for all regular season, conference tournament, and NCAAÂ® tournament games since the 2003 season (men) or since the 2010 season (women).**\n\nTeam Box Scores are provided in \"Detailed Results\" files rather than \"Compact Results\" files. However, the two files are strongly related.\n\nIn a Detailed Results file, the first eight columns (**Season, DayNum, WTeamID, WScore, LTeamID, LScore, WLoc, and NumOT**) are exactly the same as a Compact Results file. However, in a Detailed Results file, there are many additional columns. The column names should be self-explanatory to basketball fans (as above, \"W\" or \"L\" refers to the winning or losing team):\n\n- WFGM - field goals made (by the winning team)\n- WFGA - field goals attempted (by the winning team)\n- WFGM3 - three pointers made (by the winning team)\n- WFGA3 - three pointers attempted (by the winning team)\n- WFTM - free throws made (by the winning team)\n- WFTA - free throws attempted (by the winning team)\n- WOR - offensive rebounds (pulled by the winning team)\n- WDR - defensive rebounds (pulled by the winning team)\n- WAst - assists (by the winning team)\n- WTO - turnovers committed (by the winning team)\n- WStl - steals (accomplished by the winning team)\n- WBlk - blocks (accomplished by the winning team)\n- WPF - personal fouls committed (by the winning team)\n- \n(and then the same set of stats from the perspective of the losing team: **LFGM** is the number of field goals made by the losing team, and so on up to **LPF**).\n\nNote: by convention, \"field goals made\" (either WFGM or LFGM) refers to the total number of fields goals made by a team, a combination of both two-point field goals and three-point field goals. And \"three point field goals made\" (either WFGM3 or LFGM3) is just the three-point fields goals made, of course. So if you want to know specifically about two-point field goals, you have to subtract one from the other (e.g., WFGM - WFGM3). And the total number of points scored is most simply expressed as (2*FGM) + FGM3 + FTM.\n\n## Data Section 3 - Geography\n\n**This section provides city locations of all regular season, conference tournament, and NCAAÂ® tournament games since the 2010 season**\n\n## Data Section 4 - Public Rankings\n\n**This section provides weekly team rankings (men's teams only) for dozens of top rating systems - Pomeroy, Sagarin, RPI, ESPN, etc., since the 2003 season.**\n\n## Data Section 5 - Supplements\n\n**This section contains additional supporting information, including coaches, conference affiliations, alternative team name spellings, bracket structure, and game results for NIT and other postseason tournaments.**\n\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\n\ndef reduce_mem_usage(df):\n    \"\"\"\n    Reduce DataFrame memory usage by converting columns to more efficient dtypes.\n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    for col in df.columns:\n        col_type = df[col].dtype\n        if pd.api.types.is_numeric_dtype(col_type):\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if pd.api.types.is_integer_dtype(col_type):\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                else:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        elif pd.api.types.is_object_dtype(col_type) or pd.api.types.is_categorical_dtype(col_type):\n            df[col] = df[col].astype('category')\n    end_mem = df.memory_usage().sum() / 1024**2\n    return df\n\ndef load_optimized_csv(file_path):\n    \"\"\"\n    Load a CSV with memory optimization and error handling.\n    \"\"\"\n    try:\n        df = pd.read_csv(file_path, low_memory=False, encoding='utf-8')\n    except UnicodeDecodeError:\n        df = pd.read_csv(file_path, low_memory=False, encoding='ISO-8859-1')\n    except FileNotFoundError:\n        print(f\"Error: File {file_path} not found.\")\n        return None\n    df = reduce_mem_usage(df)\n    return df\n\n# Load all datasets with progress feedback\ndataset_files = {\n    \"m_teams\": \"MTeams.csv\",\n    \"w_teams\": \"WTeams.csv\",\n    \"m_seasons\": \"MSeasons.csv\",\n    \"w_seasons\": \"WSeasons.csv\",\n    \"m_tourney_seeds\": \"MNCAATourneySeeds.csv\",\n    \"w_tourney_seeds\": \"WNCAATourneySeeds.csv\",\n    \"m_regular_season_compact\": \"MRegularSeasonCompactResults.csv\",\n    \"w_regular_season_compact\": \"WRegularSeasonCompactResults.csv\",\n    \"m_tourney_compact\": \"MNCAATourneyCompactResults.csv\",\n    \"w_tourney_compact\": \"WNCAATourneyCompactResults.csv\",\n    \"m_regular_season_detailed\": \"MRegularSeasonDetailedResults.csv\",\n    \"w_regular_season_detailed\": \"WRegularSeasonDetailedResults.csv\",\n    \"m_tourney_detailed\": \"MNCAATourneyDetailedResults.csv\",\n    \"w_tourney_detailed\": \"WNCAATourneyDetailedResults.csv\",\n    \"cities\": \"Cities.csv\",\n    \"m_game_cities\": \"MGameCities.csv\",\n    \"w_game_cities\": \"WGameCities.csv\",\n    \"massey_ordinals\": \"MMasseyOrdinals.csv\",\n    \"m_team_coaches\": \"MTeamCoaches.csv\",\n    \"conferences\": \"Conferences.csv\",\n    \"m_team_conferences\": \"MTeamConferences.csv\",\n    \"w_team_conferences\": \"WTeamConferences.csv\",\n    \"m_conf_tourney_games\": \"MConferenceTourneyGames.csv\",\n    \"w_conf_tourney_games\": \"WConferenceTourneyGames.csv\",\n    \"m_secondary_tourney_teams\": \"MSecondaryTourneyTeams.csv\",\n    \"w_secondary_tourney_teams\": \"WSecondaryTourneyTeams.csv\",\n    \"m_secondary_tourney_results\": \"MSecondaryTourneyCompactResults.csv\",\n    \"w_secondary_tourney_results\": \"WSecondaryTourneyCompactResults.csv\",\n    \"m_team_spellings\": \"MTeamSpellings.csv\",\n    \"w_team_spellings\": \"WTeamSpellings.csv\",\n    \"m_tourney_slots\": \"MNCAATourneySlots.csv\",\n    \"w_tourney_slots\": \"WNCAATourneySlots.csv\",\n    \"m_seed_round_slots\": \"MNCAATourneySeedRoundSlots.csv\"\n}\n\nbase_path = \"/kaggle/input/march-machine-learning-mania-2025\"\ndataframes = {}\n\nprint(\"ðŸ”¹ Starting to load all CSV files with memory optimization...\")\nfor key, file_name in tqdm(dataset_files.items(), desc=\"Loading datasets\"):\n    full_path = f\"{base_path}/{file_name}\"\n    dataframes[key] = load_optimized_csv(full_path)\nprint(\"âœ… All files loaded into the `dataframes` dictionary.\")\n\n# Unpack into variables\n(\n    m_teams, w_teams, m_seasons, w_seasons, m_tourney_seeds, w_tourney_seeds,\n    m_regular_season_compact, w_regular_season_compact, m_tourney_compact, w_tourney_compact,\n    m_regular_season_detailed, w_regular_season_detailed, m_tourney_detailed, w_tourney_detailed,\n    cities, m_game_cities, w_game_cities, massey_ordinals, m_team_coaches, conferences,\n    m_team_conferences, w_team_conferences, m_conf_tourney_games, w_conf_tourney_games,\n    m_secondary_tourney_teams, w_secondary_tourney_teams, m_secondary_tourney_results,\n    w_secondary_tourney_results, m_team_spellings, w_team_spellings, m_tourney_slots,\n    w_tourney_slots, m_seed_round_slots\n) = dataframes.values()\n\nprint(\"âœ… Data successfully unpacked into individual DataFrames!\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-11T12:29:03.852031Z","iopub.execute_input":"2025-03-11T12:29:03.852431Z","iopub.status.idle":"2025-03-11T12:29:10.587261Z","shell.execute_reply.started":"2025-03-11T12:29:03.852397Z","shell.execute_reply":"2025-03-11T12:29:10.586229Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Exploring the Data","metadata":{}},{"cell_type":"code","source":"def summarize_dataframes(df_dict, markdown_file=\"dataset_summary.txt\"):\n    \"\"\"\n    Summarize each DataFrame, including rows, columns, missing values, duplicates, column names, dtypes, and sample rows.\n    \"\"\"\n    try:\n        import tabulate  # Required for to_markdown\n    except ImportError:\n        print(\"Warning: 'tabulate' not installed. Falling back to plain text.\")\n    \n    dataset_summary = {}\n    for name, df in df_dict.items():\n        dataset_summary[name] = {\n            \"Rows\": df.shape[0],\n            \"Columns\": df.shape[1],\n            \"Missing Values\": int(df.isnull().sum().sum()),\n            \"Duplicate Rows\": int(df.duplicated().sum()),\n            \"Column Names\": df.columns.tolist(),\n            \"Column Dtypes\": df.dtypes.astype(str).tolist(),\n            \"Sample Rows\": df.head().to_dict(orient='records')\n        }\n    \n    summary_df = pd.DataFrame(dataset_summary).T\n    print(\"ðŸ”Ž Dataset Summaries:\")\n    try:\n        display(summary_df)\n    except NameError:\n        print(summary_df)\n    \n    try:\n        summary_md = summary_df.to_markdown()\n    except (ImportError, NameError):\n        summary_md = summary_df.to_string()\n    \n    with open(markdown_file, \"w\", encoding=\"utf-8\") as f:\n        f.write(summary_md)\n    print(f\"âœ… Summary saved to '{markdown_file}'\")\n\nsummarize_dataframes(dataframes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T12:29:15.213949Z","iopub.execute_input":"2025-03-11T12:29:15.214334Z","iopub.status.idle":"2025-03-11T12:29:16.743914Z","shell.execute_reply.started":"2025-03-11T12:29:15.214301Z","shell.execute_reply":"2025-03-11T12:29:16.742682Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Data Preparation","metadata":{}},{"cell_type":"markdown","source":"###  Update Data Preparation to Include ELO","metadata":{}},{"cell_type":"code","source":"def compute_team_season_stats(detailed_results_df):\n    \"\"\"\n    Calculate advanced team statistics per season using detailed results.\n    \"\"\"\n    df_win = detailed_results_df[['Season', 'WTeamID', 'WScore', 'WFGM', 'WFGA', 'WFGM3', 'WFGA3', 'WFTM', 'WFTA', 'WOR', 'WDR', 'WAst', 'WTO', 'WStl', 'WBlk', 'WPF', 'LScore']].rename(\n        columns={'WTeamID': 'TeamID', 'WScore': 'Score', 'WFGM': 'FGM', 'WFGA': 'FGA', 'WFGM3': 'FGM3', 'WFGA3': 'FGA3', 'WFTM': 'FTM', 'WFTA': 'FTA', 'WOR': 'OR', 'WDR': 'DR', 'WAst': 'Ast', 'WTO': 'TO', 'WStl': 'Stl', 'WBlk': 'Blk', 'WPF': 'PF', 'LScore': 'OpponentScore'}\n    )\n    df_lose = detailed_results_df[['Season', 'LTeamID', 'LScore', 'LFGM', 'LFGA', 'LFGM3', 'LFGA3', 'LFTM', 'LFTA', 'LOR', 'LDR', 'LAst', 'LTO', 'LStl', 'LBlk', 'LPF', 'WScore']].rename(\n        columns={'LTeamID': 'TeamID', 'LScore': 'Score', 'LFGM': 'FGM', 'LFGA': 'FGA', 'LFGM3': 'FGM3', 'LFGA3': 'FGA3', 'LFTM': 'FTM', 'LFTA': 'FTA', 'LOR': 'OR', 'LDR': 'DR', 'LAst': 'Ast', 'LTO': 'TO', 'LStl': 'Stl', 'LBlk': 'Blk', 'LPF': 'PF', 'WScore': 'OpponentScore'}\n    )\n    all_games = pd.concat([df_win, df_lose], ignore_index=True)\n    team_stats = all_games.groupby(['Season', 'TeamID']).agg(\n        games=('TeamID', 'count'), total_points=('Score', 'sum'), total_fgm=('FGM', 'sum'), total_fga=('FGA', 'sum'),\n        total_fgm3=('FGM3', 'sum'), total_fga3=('FGA3', 'sum'), total_ftm=('FTM', 'sum'), total_fta=('FTA', 'sum'),\n        total_or=('OR', 'sum'), total_dr=('DR', 'sum'), total_ast=('Ast', 'sum'), total_to=('TO', 'sum'),\n        total_stl=('Stl', 'sum'), total_blk=('Blk', 'sum'), total_pf=('PF', 'sum'), total_points_allowed=('OpponentScore', 'sum')\n    ).reset_index()\n    team_stats['avg_points'] = team_stats['total_points'] / team_stats['games']\n    team_stats['avg_points_allowed'] = team_stats['total_points_allowed'] / team_stats['games']\n    team_stats['fg_percent'] = team_stats['total_fgm'] / team_stats['total_fga']\n    team_stats['three_p_percent'] = team_stats['total_fgm3'] / team_stats['total_fga3']\n    team_stats['ft_percent'] = team_stats['total_ftm'] / team_stats['total_fta']\n    team_stats['avg_rebounds'] = (team_stats['total_or'] + team_stats['total_dr']) / team_stats['games']\n    team_stats['avg_assists'] = team_stats['total_ast'] / team_stats['games']\n    team_stats['avg_turnovers'] = team_stats['total_to'] / team_stats['games']\n    team_stats['avg_steals'] = team_stats['total_stl'] / team_stats['games']\n    team_stats['avg_blocks'] = team_stats['total_blk'] / team_stats['games']\n    team_stats['avg_fouls'] = team_stats['total_pf'] / team_stats['games']\n    return team_stats[['Season', 'TeamID', 'avg_points', 'avg_points_allowed', 'fg_percent', 'three_p_percent', 'ft_percent', 'avg_rebounds', 'avg_assists', 'avg_turnovers', 'avg_steals', 'avg_blocks', 'avg_fouls']]\n\nprint(\"ðŸ”¹ Computing Men's Team Stats...\")\nm_team_stats = compute_team_season_stats(m_regular_season_detailed)\nprint(\"âœ… Done!\")\nprint(\"ðŸ”¹ Computing Women's Team Stats...\")\nw_team_stats = compute_team_season_stats(w_regular_season_detailed)\nprint(\"âœ… Done!\")\nm_team_stats.to_csv(\"m_team_stats.csv\", index=False)\nw_team_stats.to_csv(\"w_team_stats.csv\", index=False)\nprint(\"âœ… Team stats saved!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T12:29:21.777738Z","iopub.execute_input":"2025-03-11T12:29:21.778257Z","iopub.status.idle":"2025-03-11T12:29:22.182490Z","shell.execute_reply.started":"2025-03-11T12:29:21.778211Z","shell.execute_reply":"2025-03-11T12:29:22.181356Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Create Matchup Features for Model Training","metadata":{}},{"cell_type":"code","source":"def prepare_training_data(tourney_results, team_stats):\n    \"\"\"\n    Prepare tournament data with team stats for XGBoost training.\n    \"\"\"\n    tourney_results = tourney_results[tourney_results['Season'] < 2025].copy()\n    tourney_results['Team1'] = tourney_results[['WTeamID', 'LTeamID']].min(axis=1)\n    tourney_results['Team2'] = tourney_results[['WTeamID', 'LTeamID']].max(axis=1)\n    tourney_results['Outcome'] = (tourney_results['WTeamID'] == tourney_results['Team1']).astype(int)\n    feature_cols = ['avg_points', 'avg_points_allowed', 'fg_percent', 'three_p_percent', 'ft_percent', 'avg_rebounds', 'avg_assists', 'avg_turnovers', 'avg_steals', 'avg_blocks', 'avg_fouls']\n    team1_stats = team_stats[['Season', 'TeamID'] + feature_cols].rename(columns={col: f'Team1_{col}' for col in feature_cols})\n    team2_stats = team_stats[['Season', 'TeamID'] + feature_cols].rename(columns={col: f'Team2_{col}' for col in feature_cols})\n    train_data = tourney_results.merge(team1_stats, left_on=['Season', 'Team1'], right_on=['Season', 'TeamID'], how='left').drop('TeamID', axis=1)\n    train_data = train_data.merge(team2_stats, left_on=['Season', 'Team2'], right_on=['Season', 'TeamID'], how='left').drop('TeamID', axis=1)\n    return train_data, feature_cols\n\nprint(\"ðŸ”¹ Preparing Men's Training Data...\")\nm_train_data, feature_cols = prepare_training_data(m_tourney_compact, m_team_stats)\nprint(\"âœ… Done!\")\nprint(\"ðŸ”¹ Preparing Women's Training Data...\")\nw_train_data, _ = prepare_training_data(w_tourney_compact, w_team_stats)\nprint(\"âœ… Done!\")\nm_train_data.to_csv(\"m_training_data.csv\", index=False)\nw_train_data.to_csv(\"w_training_data.csv\", index=False)\nprint(\"âœ… Training data saved!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T12:29:32.030930Z","iopub.execute_input":"2025-03-11T12:29:32.031350Z","iopub.status.idle":"2025-03-11T12:29:32.174695Z","shell.execute_reply.started":"2025-03-11T12:29:32.031313Z","shell.execute_reply":"2025-03-11T12:29:32.173675Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Computing ELO Ratings and Submission","metadata":{}},{"cell_type":"code","source":"import itertools\nimport pandas as pd\nimport numpy as np\nfrom xgboost import XGBClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import brier_score_loss\n\ndef compute_elo_ratings(regular_season_df, start_elo=1500, k_factor=20, season_scoped=True, home_advantage=100):\n    \"\"\"\n    Compute ELO ratings with home-court advantage and margin-of-victory.\n    \"\"\"\n    regular_season_df = regular_season_df.sort_values(by=['Season', 'DayNum']).reset_index(drop=True)\n    elo_dict = {}\n    for _, row in regular_season_df.iterrows():\n        season = int(row['Season'])\n        w_tid = int(row['WTeamID'])\n        l_tid = int(row['LTeamID'])\n        w_score = row['WScore']\n        l_score = row['LScore']\n        wloc = row['WLoc']\n        w_key = (season, w_tid) if season_scoped else w_tid\n        l_key = (season, l_tid) if season_scoped else l_tid\n        if w_key not in elo_dict:\n            elo_dict[w_key] = start_elo\n        if l_key not in elo_dict:\n            elo_dict[l_key] = start_elo\n        w_elo = elo_dict[w_key]\n        l_elo = elo_dict[l_key]\n        if wloc == 'H':\n            exp_w = 1.0 / (1.0 + 10.0 ** ((l_elo - (w_elo + home_advantage)) / 400.0))\n        elif wloc == 'A':\n            exp_w = 1.0 / (1.0 + 10.0 ** (((l_elo + home_advantage) - w_elo) / 400.0))\n        else:\n            exp_w = 1.0 / (1.0 + 10.0 ** ((l_elo - w_elo) / 400.0))\n        point_diff = w_score - l_score\n        mov_factor = np.log2(point_diff + 1) * (2.2 / ((w_elo - l_elo) * 0.001 + 2.2))\n        elo_dict[w_key] = w_elo + k_factor * mov_factor * (1.0 - exp_w)\n        elo_dict[l_key] = l_elo + k_factor * mov_factor * (0.0 - (1.0 - exp_w))\n    return elo_dict\n\nprint(\"ðŸ”¹ Computing Men's ELO...\")\nm_elo_dict = compute_elo_ratings(m_regular_season_compact)\nprint(\"âœ… Done!\")\nprint(\"ðŸ”¹ Computing Women's ELO...\")\nw_elo_dict = compute_elo_ratings(w_regular_season_compact)\nprint(\"âœ… Done!\")\n\nteam1_feats = [f'Team1_{col}' for col in feature_cols]\nteam2_feats = [f'Team2_{col}' for col in feature_cols]\nX_train_m = m_train_data[team1_feats + team2_feats].fillna(0)\ny_train_m = m_train_data['Outcome']\nxgb_model_m = XGBClassifier(objective='binary:logistic', eval_metric='logloss', random_state=42)\nxgb_model_m.fit(X_train_m, y_train_m)\nprint(\"âœ… Men's XGBoost Trained!\")\n\nX_train_w = w_train_data[team1_feats + team2_feats].fillna(0)\ny_train_w = w_train_data['Outcome']\nxgb_model_w = XGBClassifier(objective='binary:logistic', eval_metric='logloss', random_state=42)\nxgb_model_w.fit(X_train_w, y_train_w)\nprint(\"âœ… Women's XGBoost Trained!\")\n\ndef add_elo_to_train_data(train_data, elo_dict):\n    \"\"\"\n    Add ELO ratings to training data, ensuring no duplicate columns.\n    \"\"\"\n    elo_df = pd.DataFrame([(k[0], k[1], v) for k, v in elo_dict.items()], columns=['Season', 'TeamID', 'ELO'])\n    elo_df = elo_df.drop_duplicates(subset=['Season', 'TeamID'])\n    train_data = train_data.copy()\n    for col in ['Team1_ELO', 'Team2_ELO']:\n        if col in train_data.columns:\n            train_data = train_data.drop(columns=[col])\n    train_data = train_data.merge(\n        elo_df, left_on=['Season', 'Team1'], right_on=['Season', 'TeamID'], \n        how='left', suffixes=('', '_drop')\n    ).rename(columns={'ELO': 'Team1_ELO'}).drop('TeamID', axis=1)\n    train_data = train_data.merge(\n        elo_df, left_on=['Season', 'Team2'], right_on=['Season', 'TeamID'], \n        how='left', suffixes=('', '_drop')\n    ).rename(columns={'ELO': 'Team2_ELO'}).drop('TeamID', axis=1)\n    train_data = train_data.loc[:, ~train_data.columns.str.endswith('_drop')]\n    return train_data\n\n# After XGBoost training\nprint(\"Shape of m_train_data before adding ELO:\", m_train_data.shape)\nprint(\"Shape of w_train_data before adding ELO:\", w_train_data.shape)\nprint(\"Length of X_train_m:\", len(X_train_m))\nprint(\"Length of y_train_m:\", len(y_train_m))\nprint(\"Length of X_train_w:\", len(X_train_w))\nprint(\"Length of y_train_w:\", len(y_train_w))\n\nm_train_data = add_elo_to_train_data(m_train_data, m_elo_dict)\nw_train_data = add_elo_to_train_data(w_train_data, w_elo_dict)\n\nprint(\"Shape of m_train_data after adding ELO:\", m_train_data.shape)\nprint(\"Columns in m_train_data:\", m_train_data.columns.tolist())\nprint(\"Missing Team1_ELO in m_train_data:\", m_train_data['Team1_ELO'].isna().sum())\nprint(\"Missing Team2_ELO in m_train_data:\", m_train_data['Team2_ELO'].isna().sum())\nprint(\"Shape of w_train_data after adding ELO:\", w_train_data.shape)\nprint(\"Columns in w_train_data:\", w_train_data.columns.tolist())\nprint(\"Missing Team1_ELO in w_train_data:\", w_train_data['Team1_ELO'].isna().sum())\nprint(\"Missing Team2_ELO in w_train_data:\", w_train_data['Team2_ELO'].isna().sum())\n\nm_train_data['Team1_ELO'] = m_train_data['Team1_ELO'].fillna(1500)\nm_train_data['Team2_ELO'] = m_train_data['Team2_ELO'].fillna(1500)\nw_train_data['Team1_ELO'] = w_train_data['Team1_ELO'].fillna(1500)\nw_train_data['Team2_ELO'] = w_train_data['Team2_ELO'].fillna(1500)\n\nm_train_data['ELO_prob'] = 1 / (1 + 10 ** ((m_train_data['Team2_ELO'] - m_train_data['Team1_ELO']) / 400))\nm_train_data['XGBoost_prob'] = xgb_model_m.predict_proba(X_train_m)[:, 1]\nm_train_data['avg_prob'] = (m_train_data['ELO_prob'] + m_train_data['XGBoost_prob']) / 2\n\nw_train_data['ELO_prob'] = 1 / (1 + 10 ** ((w_train_data['Team2_ELO'] - w_train_data['Team1_ELO']) / 400))\nw_train_data['XGBoost_prob'] = xgb_model_w.predict_proba(X_train_w)[:, 1]\nw_train_data['avg_prob'] = (w_train_data['ELO_prob'] + w_train_data['XGBoost_prob']) / 2\n\nassert len(m_train_data) == len(X_train_m) == len(y_train_m), \"Mismatch in m_train_data, X_train_m, y_train_m lengths\"\nassert len(w_train_data) == len(X_train_w) == len(y_train_w), \"Mismatch in w_train_data, X_train_w, y_train_w lengths\"\n\ncalibrator_m = LogisticRegression(random_state=42).fit(m_train_data['avg_prob'].values.reshape(-1, 1), y_train_m)\ncalibrator_w = LogisticRegression(random_state=42).fit(w_train_data['avg_prob'].values.reshape(-1, 1), y_train_w)\nprint(\"âœ… Calibrators Fitted!\")\n\n# --- Brier Score Validation on 2024 Tournament ---\nprint(\"ðŸ”¹ Calculating Brier Score on 2024 Validation Set...\")\n\n# Filter 2024 tournament games (assuming these are not in training data)\nm_tourney_2024 = m_tourney_compact[m_tourney_compact['Season'] == 2024].copy()\nw_tourney_2024 = w_tourney_compact[w_tourney_compact['Season'] == 2024].copy()\n\n# Prepare validation data (reusing prepare_training_data from earlier)\nm_val_data, _ = prepare_training_data(m_tourney_2024, m_team_stats)\nw_val_data, _ = prepare_training_data(w_tourney_2024, w_team_stats)\n\n# Add ELO ratings to validation data\nm_val_data = add_elo_to_train_data(m_val_data, m_elo_dict)\nw_val_data = add_elo_to_train_data(w_val_data, w_elo_dict)\n\n# Handle NaNs in validation data\nm_val_data['Team1_ELO'] = m_val_data['Team1_ELO'].fillna(1500)\nm_val_data['Team2_ELO'] = m_val_data['Team2_ELO'].fillna(1500)\nw_val_data['Team1_ELO'] = w_val_data['Team1_ELO'].fillna(1500)\nw_val_data['Team2_ELO'] = w_val_data['Team2_ELO'].fillna(1500)\n\n# Compute ELO probabilities\nm_val_data['ELO_prob'] = 1 / (1 + 10 ** ((m_val_data['Team2_ELO'] - m_val_data['Team1_ELO']) / 400))\nw_val_data['ELO_prob'] = 1 / (1 + 10 ** ((w_val_data['Team2_ELO'] - w_val_data['Team1_ELO']) / 400))\n\n# Compute XGBoost probabilities\nX_val_m = m_val_data[team1_feats + team2_feats].fillna(0)\nm_val_data['XGBoost_prob'] = xgb_model_m.predict_proba(X_val_m)[:, 1]\nX_val_w = w_val_data[team1_feats + team2_feats].fillna(0)\nw_val_data['XGBoost_prob'] = xgb_model_w.predict_proba(X_val_w)[:, 1]\n\n# Average probabilities\nm_val_data['avg_prob'] = (m_val_data['ELO_prob'] + m_val_data['XGBoost_prob']) / 2\nw_val_data['avg_prob'] = (w_val_data['ELO_prob'] + w_val_data['XGBoost_prob']) / 2\n\n# Calibrate probabilities\nm_val_data['calibrated_prob'] = calibrator_m.predict_proba(m_val_data['avg_prob'].values.reshape(-1, 1))[:, 1]\nw_val_data['calibrated_prob'] = calibrator_w.predict_proba(w_val_data['avg_prob'].values.reshape(-1, 1))[:, 1]\n\n# Calculate Brier Score\nm_brier = brier_score_loss(m_val_data['Outcome'], m_val_data['calibrated_prob'])\nw_brier = brier_score_loss(w_val_data['Outcome'], w_val_data['calibrated_prob'])\nprint(f\"Men's 2024 Brier Score: {m_brier:.4f}\")\nprint(f\"Women's 2024 Brier Score: {w_brier:.4f}\")\nprint(f\"Average Brier Score: {(m_brier + w_brier) / 2:.4f}\")\nprint(\"âœ… Validation Complete!\")\n# --- End of Brier Score Validation ---\n\ndef extract_final_season_elo(elo_dict, season=2025):\n    df = pd.DataFrame([((season, tid), elo) for (s, tid), elo in elo_dict.items() if s == season], columns=['key', 'Final_ELO'])\n    df['TeamID'] = df['key'].apply(lambda k: k[1])\n    return df.drop('key', axis=1)\n\nm_teams_2025_elo = extract_final_season_elo(m_elo_dict, 2025)\nw_teams_2025_elo = extract_final_season_elo(w_elo_dict, 2025)\nm_team_stats_2025 = m_team_stats[m_team_stats['Season'] == 2025]\nw_team_stats_2025 = w_team_stats[w_team_stats['Season'] == 2025]\n\nm_teams_2025_ids = m_team_conferences[m_team_conferences['Season'] == 2025]['TeamID'].unique()\nw_teams_2025_ids = w_team_conferences[w_team_conferences['Season'] == 2025]['TeamID'].unique()\nm_matchups = list(itertools.combinations(sorted(m_teams_2025_ids), 2))\nw_matchups = list(itertools.combinations(sorted(w_teams_2025_ids), 2))\nprint(f\"Men's Matchups: {len(m_matchups)}, Women's Matchups: {len(w_matchups)}\")\n\ndef compute_submission_rows(matchups, elo_df, team_stats_df, xgb_model, calibrator, season=2025):\n    rows = []\n    for t1, t2 in matchups:\n        row_id = f\"{season}_{t1}_{t2}\"\n        elo_t1 = elo_df.loc[elo_df['TeamID'] == t1, 'Final_ELO'].iloc[0] if t1 in elo_df['TeamID'].values else 1500\n        elo_t2 = elo_df.loc[elo_df['TeamID'] == t2, 'Final_ELO'].iloc[0] if t2 in elo_df['TeamID'].values else 1500\n        elo_prob = 1 / (1 + 10 ** ((elo_t2 - elo_t1) / 400))\n        stats_t1 = team_stats_df.loc[team_stats_df['TeamID'] == t1, feature_cols].iloc[0] if t1 in team_stats_df['TeamID'].values else pd.Series(0, index=feature_cols)\n        stats_t2 = team_stats_df.loc[team_stats_df['TeamID'] == t2, feature_cols].iloc[0] if t2 in team_stats_df['TeamID'].values else pd.Series(0, index=feature_cols)\n        xgb_feats = np.concatenate([stats_t1.values, stats_t2.values])\n        xgb_prob = xgb_model.predict_proba([xgb_feats])[0, 1]\n        avg_prob = (elo_prob + xgb_prob) / 2\n        final_prob = calibrator.predict_proba([[avg_prob]])[0, 1]\n        rows.append((row_id, final_prob))\n    return rows\n\nprint(\"ðŸ”¹ Generating Submission...\")\nm_rows = compute_submission_rows(m_matchups, m_teams_2025_elo, m_team_stats_2025, xgb_model_m, calibrator_m)\nw_rows = compute_submission_rows(w_matchups, w_teams_2025_elo, w_team_stats_2025, xgb_model_w, calibrator_w)\nsubmission_data = pd.DataFrame(m_rows + w_rows, columns=[\"ID\", \"Pred\"])\nsubmission_data.to_csv(\"submission.csv\", index=False)\nprint(f\"âœ… Submission Saved! Total Rows: {len(submission_data)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T12:29:39.223951Z","iopub.execute_input":"2025-03-11T12:29:39.224438Z","iopub.status.idle":"2025-03-11T12:39:43.879831Z","shell.execute_reply.started":"2025-03-11T12:29:39.224397Z","shell.execute_reply":"2025-03-11T12:39:43.878595Z"}},"outputs":[],"execution_count":null}]}