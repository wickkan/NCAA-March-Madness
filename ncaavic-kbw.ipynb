{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91497,"databundleVersionId":11165145,"sourceType":"competition"}],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Loading in data","metadata":{}},{"cell_type":"markdown","source":"## Data Section 1 - The Basics\n\n**This section provides everything you need to build a simple prediction model and submit predictions.**\n\n- Team ID's and Team Names\n- Tournament seeds since 1984-85 season\n- Final scores of all regular season, conference tournament, and NCAA® tournament games since 1984-85 season\n- Season-level details including dates and region names\n- Example submission file for stage 1\n  \nBy convention, when we identify a particular season, we will reference the year that the season ends in, not the year that it starts in.\n\n## Data Section 2 - Team Box Scores\n\n**This section provides game-by-game stats at a team level (free throws attempted, defensive rebounds, turnovers, etc.) for all regular season, conference tournament, and NCAA® tournament games since the 2003 season (men) or since the 2010 season (women).**\n\nTeam Box Scores are provided in \"Detailed Results\" files rather than \"Compact Results\" files. However, the two files are strongly related.\n\nIn a Detailed Results file, the first eight columns (**Season, DayNum, WTeamID, WScore, LTeamID, LScore, WLoc, and NumOT**) are exactly the same as a Compact Results file. However, in a Detailed Results file, there are many additional columns. The column names should be self-explanatory to basketball fans (as above, \"W\" or \"L\" refers to the winning or losing team):\n\n- WFGM - field goals made (by the winning team)\n- WFGA - field goals attempted (by the winning team)\n- WFGM3 - three pointers made (by the winning team)\n- WFGA3 - three pointers attempted (by the winning team)\n- WFTM - free throws made (by the winning team)\n- WFTA - free throws attempted (by the winning team)\n- WOR - offensive rebounds (pulled by the winning team)\n- WDR - defensive rebounds (pulled by the winning team)\n- WAst - assists (by the winning team)\n- WTO - turnovers committed (by the winning team)\n- WStl - steals (accomplished by the winning team)\n- WBlk - blocks (accomplished by the winning team)\n- WPF - personal fouls committed (by the winning team)\n- \n(and then the same set of stats from the perspective of the losing team: **LFGM** is the number of field goals made by the losing team, and so on up to **LPF**).\n\nNote: by convention, \"field goals made\" (either WFGM or LFGM) refers to the total number of fields goals made by a team, a combination of both two-point field goals and three-point field goals. And \"three point field goals made\" (either WFGM3 or LFGM3) is just the three-point fields goals made, of course. So if you want to know specifically about two-point field goals, you have to subtract one from the other (e.g., WFGM - WFGM3). And the total number of points scored is most simply expressed as (2*FGM) + FGM3 + FTM.\n\n## Data Section 3 - Geography\n\n**This section provides city locations of all regular season, conference tournament, and NCAA® tournament games since the 2010 season**\n\n## Data Section 4 - Public Rankings\n\n**This section provides weekly team rankings (men's teams only) for dozens of top rating systems - Pomeroy, Sagarin, RPI, ESPN, etc., since the 2003 season.**\n\n## Data Section 5 - Supplements\n\n**This section contains additional supporting information, including coaches, conference affiliations, alternative team name spellings, bracket structure, and game results for NIT and other postseason tournaments.**\n\n","metadata":{}},{"cell_type":"code","source":"import itertools\nimport pandas as pd\nimport numpy as np\nfrom sklearn.metrics import brier_score_loss, mean_squared_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\n\n\n# Function to reduce memory usage\ndef reduce_mem_usage(df):\n    \"\"\" Reduces memory usage by optimizing data types. \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n\n    for col in df.columns:\n        col_type = df[col].dtype\n\n        if col_type != object:\n            c_min, c_max = df[col].min(), df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                else:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    return df\n\n# Efficient Data Loading with Memory Optimization\ndef load_optimized_csv(file_path):\n    \"\"\" Load CSV file with memory optimization & error handling for encoding issues. \"\"\"\n    df = pd.read_csv(file_path, encoding='ISO-8859-1') \n    df = reduce_mem_usage(df)\n    return df\n\n# Load all other necessary Kaggle datasets efficiently\ndataset_files = {\n    \"m_teams\": \"MTeams.csv\",\n    \"w_teams\": \"WTeams.csv\",\n    \"m_seasons\": \"MSeasons.csv\",\n    \"w_seasons\": \"WSeasons.csv\",\n    \"m_tourney_seeds\": \"MNCAATourneySeeds.csv\",\n    \"w_tourney_seeds\": \"WNCAATourneySeeds.csv\",\n    \"m_regular_season_compact\": \"MRegularSeasonCompactResults.csv\",\n    \"w_regular_season_compact\": \"WRegularSeasonCompactResults.csv\",\n    \"m_tourney_compact\": \"MNCAATourneyCompactResults.csv\",\n    \"w_tourney_compact\": \"WNCAATourneyCompactResults.csv\",\n    \"m_regular_season_detailed\": \"MRegularSeasonDetailedResults.csv\",\n    \"w_regular_season_detailed\": \"WRegularSeasonDetailedResults.csv\",\n    \"m_tourney_detailed\": \"MNCAATourneyDetailedResults.csv\",\n    \"w_tourney_detailed\": \"WNCAATourneyDetailedResults.csv\",\n    \"cities\": \"Cities.csv\",\n    \"m_game_cities\": \"MGameCities.csv\",\n    \"w_game_cities\": \"WGameCities.csv\",\n    \"massey_ordinals\": \"MMasseyOrdinals.csv\",\n    \"m_team_coaches\": \"MTeamCoaches.csv\",\n    \"conferences\": \"Conferences.csv\",\n    \"m_team_conferences\": \"MTeamConferences.csv\",\n    \"w_team_conferences\": \"WTeamConferences.csv\",\n    \"m_conf_tourney_games\": \"MConferenceTourneyGames.csv\",\n    \"w_conf_tourney_games\": \"WConferenceTourneyGames.csv\",\n    \"m_secondary_tourney_teams\": \"MSecondaryTourneyTeams.csv\",\n    \"w_secondary_tourney_teams\": \"WSecondaryTourneyTeams.csv\",\n    \"m_secondary_tourney_results\": \"MSecondaryTourneyCompactResults.csv\",\n    \"w_secondary_tourney_results\": \"WSecondaryTourneyCompactResults.csv\",\n    \"m_team_spellings\": \"MTeamSpellings.csv\",\n    \"w_team_spellings\": \"WTeamSpellings.csv\",\n    \"m_tourney_slots\": \"MNCAATourneySlots.csv\",\n    \"w_tourney_slots\": \"WNCAATourneySlots.csv\",\n    \"m_seed_round_slots\": \"MNCAATourneySeedRoundSlots.csv\"\n}\n\n# Load all datasets with memory optimization\ndataframes = {}\n\nfor key, file_name in dataset_files.items():\n    dataframes[key] = load_optimized_csv(f\"/kaggle/input/march-machine-learning-mania-2025/{file_name}\")\n\n# Unpack dataframes into individual variables\n(\n    m_teams, w_teams, m_seasons, w_seasons, m_tourney_seeds, w_tourney_seeds,\n    m_regular_season_compact, w_regular_season_compact, m_tourney_compact, w_tourney_compact,\n    m_regular_season_detailed, w_regular_season_detailed, m_tourney_detailed, w_tourney_detailed,\n    cities, m_game_cities, w_game_cities, massey_ordinals, m_team_coaches, conferences,\n    m_team_conferences, w_team_conferences, m_conf_tourney_games, w_conf_tourney_games,\n    m_secondary_tourney_teams, w_secondary_tourney_teams, m_secondary_tourney_results,\n    w_secondary_tourney_results, m_team_spellings, w_team_spellings, m_tourney_slots,\n    w_tourney_slots, m_seed_round_slots\n) = dataframes.values()\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-21T07:31:35.872706Z","iopub.execute_input":"2025-02-21T07:31:35.873097Z","iopub.status.idle":"2025-02-21T07:31:39.837503Z","shell.execute_reply.started":"2025-02-21T07:31:35.873069Z","shell.execute_reply":"2025-02-21T07:31:39.836272Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Exploring the Data","metadata":{}},{"cell_type":"code","source":"# Create summary of each dataset\ndataset_summary = {}\n\nfor name, df in dataframes.items():  # Fix: Use correct variable name `dataframes`\n    dataset_summary[name] = {\n        \"Rows\": df.shape[0],\n        \"Columns\": df.shape[1],\n        \"Missing Values\": df.isnull().sum().sum(),\n        \"Duplicate Rows\": df.duplicated().sum(),\n        \"First 5 Rows\": df.head().to_dict(),  # Convert to dict to avoid display issues\n        \"Column Names\": df.columns.tolist()\n    }\n\n# Convert summary to DataFrame\nsummary_df = pd.DataFrame(dataset_summary).T\n\n# Display dataset summaries\ndisplay(summary_df)  # Works in notebooks\n\n# Try converting to Markdown format (fallback to .to_string() if .to_markdown() is unavailable)\ntry:\n    summary_md = summary_df.to_markdown()\nexcept ImportError:\n    summary_md = summary_df.to_string()\n\n# Save as a text file\nwith open(\"dataset_summary.txt\", \"w\", encoding=\"utf-8\") as f:\n    f.write(summary_md)\n\nprint(\"✅ Dataset summary saved as 'dataset_summary.txt'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T07:27:09.943986Z","iopub.execute_input":"2025-02-21T07:27:09.944520Z","iopub.status.idle":"2025-02-21T07:27:11.633958Z","shell.execute_reply.started":"2025-02-21T07:27:09.944432Z","shell.execute_reply":"2025-02-21T07:27:11.632391Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Data Preparation","metadata":{}},{"cell_type":"markdown","source":"### Compute Team-Level Stats from Regular Season","metadata":{}},{"cell_type":"code","source":"# Function to compute team-level season stats from regular season results\ndef compute_team_stats(regular_season_df):\n    \"\"\"Compute season stats for each team from regular season results.\"\"\"\n\n    # Compute stats for winning teams\n    win_stats = regular_season_df.groupby(['Season', 'WTeamID']).agg(\n        Wins=('WTeamID', 'count'),\n        Points_Scored_Win=('WScore', 'sum'),\n        Points_Allowed_Win=('LScore', 'sum')\n    ).reset_index().rename(columns={'WTeamID': 'TeamID'})\n\n    # Compute stats for losing teams\n    loss_stats = regular_season_df.groupby(['Season', 'LTeamID']).agg(\n        Losses=('LTeamID', 'count'),\n        Points_Scored_Loss=('LScore', 'sum'),\n        Points_Allowed_Loss=('WScore', 'sum')\n    ).reset_index().rename(columns={'LTeamID': 'TeamID'})\n\n    # Merge win/loss stats\n    team_stats = pd.merge(win_stats, loss_stats, on=['Season', 'TeamID'], how='outer').fillna(0)\n\n    # Compute additional features\n    team_stats['TotalGames'] = team_stats['Wins'] + team_stats['Losses']\n\n    # Avoid division by zero\n    team_stats['WinRatio'] = team_stats['Wins'] / team_stats['TotalGames'].replace(0, 1)\n\n    team_stats['AvgPointsScored'] = (team_stats['Points_Scored_Win'] + team_stats['Points_Scored_Loss']) / team_stats['TotalGames'].replace(0, 1)\n    team_stats['AvgPointsAllowed'] = (team_stats['Points_Allowed_Win'] + team_stats['Points_Allowed_Loss']) / team_stats['TotalGames'].replace(0, 1)\n    team_stats['PointMargin'] = team_stats['AvgPointsScored'] - team_stats['AvgPointsAllowed']\n\n    # Drop redundant columns\n    team_stats.drop(columns=['Points_Scored_Win', 'Points_Scored_Loss', 'Points_Allowed_Win', 'Points_Allowed_Loss'], inplace=True)\n\n    # Optimize memory usage\n    team_stats = team_stats.astype({\n        \"Season\": \"int16\",\n        \"TeamID\": \"int16\",\n        \"Wins\": \"int16\",\n        \"Losses\": \"int16\",\n        \"TotalGames\": \"int16\",\n        \"WinRatio\": \"float16\",\n        \"AvgPointsScored\": \"float16\",\n        \"AvgPointsAllowed\": \"float16\",\n        \"PointMargin\": \"float16\"\n    })\n\n    return team_stats\n\n# Compute stats for men's and women's teams\nm_team_stats = compute_team_stats(m_regular_season_compact)\nw_team_stats = compute_team_stats(w_regular_season_compact)\n\n# Display computed stats\nprint(\"Men's Team Stats Sample:\")\nprint(m_team_stats.head())\n\nprint(\"\\nWomen's Team Stats Sample:\")\nprint(w_team_stats.head())\n\n# Save to CSV \nm_team_stats.to_csv(\"m_team_stats.csv\", index=False)\nw_team_stats.to_csv(\"w_team_stats.csv\", index=False)\n\nprint(\"\\n✅ Team stats saved successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T07:28:35.779534Z","iopub.execute_input":"2025-02-21T07:28:35.780031Z","iopub.status.idle":"2025-02-21T07:28:36.056224Z","shell.execute_reply.started":"2025-02-21T07:28:35.779997Z","shell.execute_reply":"2025-02-21T07:28:36.054552Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Create Matchup Features for Model Training","metadata":{}},{"cell_type":"markdown","source":"Each matchup will include:\n- Team A and Team B stats (from the team stats dataset).\n- Feature differences (Team A - Team B).\n- Tournament seeding for both teams.\n- Target variable (Win = 1, Loss = 0).","metadata":{}},{"cell_type":"code","source":"# Function to create matchup features\ndef create_matchup_features(tourney_results, team_stats, seeds):\n    \"\"\"Generate training features for tournament matchups.\"\"\"\n    \n    # Merge winning and losing team stats\n    df = tourney_results.merge(team_stats, left_on=['Season', 'WTeamID'], right_on=['Season', 'TeamID'], suffixes=('_W', '_L'))\n    df = df.merge(team_stats, left_on=['Season', 'LTeamID'], right_on=['Season', 'TeamID'], suffixes=('_Winner', '_Loser'))\n\n    # Drop redundant columns\n    df.drop(columns=['TeamID_Winner', 'TeamID_Loser'], inplace=True)\n\n    # Merge seeding data correctly (avoid overwriting)\n    seeds_w = seeds.rename(columns={'TeamID': 'WTeamID', 'Seed': 'Seed_Winner'})\n    df = df.merge(seeds_w, on=['Season', 'WTeamID'], how='left')\n\n    seeds_l = seeds.rename(columns={'TeamID': 'LTeamID', 'Seed': 'Seed_Loser'})\n    df = df.merge(seeds_l, on=['Season', 'LTeamID'], how='left')\n\n    # Convert seeding to numeric (extract numbers from \"Seed_WXX\" format)\n    df['Seed_Winner'] = df['Seed_Winner'].str.extract('(\\d+)').astype(float).fillna(17)  # Default to 17 if missing\n    df['Seed_Loser'] = df['Seed_Loser'].str.extract('(\\d+)').astype(float).fillna(17)\n\n    # Compute matchup feature differences (Team A - Team B)\n    df['WinRatio_Diff'] = df['WinRatio_Winner'] - df['WinRatio_Loser']\n    df['PointMargin_Diff'] = df['PointMargin_Winner'] - df['PointMargin_Loser']\n    df['AvgPointsScored_Diff'] = df['AvgPointsScored_Winner'] - df['AvgPointsScored_Loser']\n    df['AvgPointsAllowed_Diff'] = df['AvgPointsAllowed_Winner'] - df['AvgPointsAllowed_Loser']\n    df['Seed_Diff'] = df['Seed_Loser'] - df['Seed_Winner']\n\n    # Ensure Target reflects the competition format (1 if lower TeamID wins)\n    df['Target'] = (df['WTeamID'] < df['LTeamID']).astype(int)\n\n    # Optimize data types\n    df = df.astype({\n        \"Season\": \"int16\",\n        \"WTeamID\": \"int16\",\n        \"LTeamID\": \"int16\",\n        \"Seed_Winner\": \"int8\",\n        \"Seed_Loser\": \"int8\",\n        \"WinRatio_Diff\": \"float16\",\n        \"PointMargin_Diff\": \"float16\",\n        \"AvgPointsScored_Diff\": \"float16\",\n        \"AvgPointsAllowed_Diff\": \"float16\",\n        \"Seed_Diff\": \"int8\",\n        \"Target\": \"int8\"\n    })\n\n    return df\n\n# Generate matchup data for training\nm_training_data = create_matchup_features(m_tourney_compact, m_team_stats, m_tourney_seeds)\nw_training_data = create_matchup_features(w_tourney_compact, w_team_stats, w_tourney_seeds)\n\n# Display processed training data\nprint(\"Men's Training Data Sample:\")\nprint(m_training_data.head())\n\nprint(\"\\nWomen's Training Data Sample:\")\nprint(w_training_data.head())\n\n# Save to CSV \nm_training_data.to_csv(\"m_training_data.csv\", index=False)\nw_training_data.to_csv(\"w_training_data.csv\", index=False)\n\nprint(\"\\n✅ Training data saved successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T07:30:09.890239Z","iopub.execute_input":"2025-02-21T07:30:09.890749Z","iopub.status.idle":"2025-02-21T07:30:10.070094Z","shell.execute_reply.started":"2025-02-21T07:30:09.890711Z","shell.execute_reply":"2025-02-21T07:30:10.068931Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Make predictions","metadata":{}},{"cell_type":"code","source":"# Load the prepared training datasets\nm_training_data = pd.read_csv(\"m_training_data.csv\")\nw_training_data = pd.read_csv(\"w_training_data.csv\")\n\n# Select features and target variable\nFEATURES = [\"WinRatio_Diff\", \"PointMargin_Diff\", \"AvgPointsScored_Diff\", \"AvgPointsAllowed_Diff\", \"Seed_Diff\"]\nTARGET = \"Target\"\n\n# Function to split data into training and validation sets\ndef split_data(df, test_season=2024):\n    \"\"\"Splits the data into training and validation sets.\"\"\"\n    train_data = df[df[\"Season\"] < test_season].copy()\n    test_data = df[df[\"Season\"] == test_season].copy()\n    \n    X_train, y_train = train_data[FEATURES], train_data[TARGET]\n    X_test, y_test = test_data[FEATURES], test_data[TARGET]\n\n    # Handle missing values (Fixed Warning)\n    X_train = X_train.fillna(0)\n    X_test = X_test.fillna(0)\n\n    return X_train, X_test, y_train, y_test\n\n# Split data for men’s and women’s tournaments\nX_train_m, X_test_m, y_train_m, y_test_m = split_data(m_training_data)\nX_train_w, X_test_w, y_train_w, y_test_w = split_data(w_training_data)\n\n# Standardize features (important for Logistic Regression)\nscaler_m = StandardScaler().fit(X_train_m)\nscaler_w = StandardScaler().fit(X_train_w)\n\nX_train_m = scaler_m.transform(X_train_m)\nX_test_m = scaler_m.transform(X_test_m)\n\nX_train_w = scaler_w.transform(X_train_w)\nX_test_w = scaler_w.transform(X_test_w)\n\n# Train Logistic Regression Model with regularization (better performance)\nmodel_m = LogisticRegression(C=1.0, solver='liblinear', random_state=42)\nmodel_w = LogisticRegression(C=1.0, solver='liblinear', random_state=42)\n\n# Train models\nmodel_m.fit(X_train_m, y_train_m)\nmodel_w.fit(X_train_w, y_train_w)\n\n# Make predictions (probability of lower TeamID winning)\ny_pred_m = model_m.predict_proba(X_test_m)[:, 1]\ny_pred_w = model_w.predict_proba(X_test_w)[:, 1]\n\n# Evaluate the model using Brier Score\nbrier_m = brier_score_loss(y_test_m, y_pred_m)\nbrier_w = brier_score_loss(y_test_w, y_pred_w)\n\nprint(f\"✅ Men's Brier Score: {brier_m:.4f}\")\nprint(f\"✅ Women's Brier Score: {brier_w:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T07:35:00.623228Z","iopub.execute_input":"2025-02-21T07:35:00.623761Z","iopub.status.idle":"2025-02-21T07:35:00.681825Z","shell.execute_reply.started":"2025-02-21T07:35:00.623722Z","shell.execute_reply":"2025-02-21T07:35:00.680460Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport itertools\n\n# Load necessary data\ndef load_team_stats(file_path):\n    \"\"\"Load relevant columns from team stats dataset.\"\"\"\n    cols_needed = [\"Season\", \"TeamID\", \"WinRatio\", \"PointMargin\", \"AvgPointsScored\", \"AvgPointsAllowed\"]\n    return pd.read_csv(file_path, usecols=cols_needed)\n\nm_team_stats = load_team_stats(\"m_team_stats.csv\")\nw_team_stats = load_team_stats(\"w_team_stats.csv\")\n\nm_tourney_seeds = pd.read_csv(\"/kaggle/input/march-machine-learning-mania-2025/MNCAATourneySeeds.csv\")\nw_tourney_seeds = pd.read_csv(\"/kaggle/input/march-machine-learning-mania-2025/WNCAATourneySeeds.csv\")\n\n# Filter teams & seeds for the 2025 season\nm_teams_2025 = m_team_stats[m_team_stats[\"Season\"] == 2025].copy()\nw_teams_2025 = w_team_stats[w_team_stats[\"Season\"] == 2025].copy()\n\nm_seeds_2025 = m_tourney_seeds[m_tourney_seeds[\"Season\"] == 2025].copy()\nw_seeds_2025 = w_tourney_seeds[w_tourney_seeds[\"Season\"] == 2025].copy()\n\n# Convert seeds to numeric\nm_seeds_2025[\"Seed\"] = m_seeds_2025[\"Seed\"].str.extract(\"(\\d+)\").astype(float)\nw_seeds_2025[\"Seed\"] = w_seeds_2025[\"Seed\"].str.extract(\"(\\d+)\").astype(float)\n\n# Generate all possible matchups\ndef generate_matchups(team_stats):\n    teams = team_stats[\"TeamID\"].unique()\n    return pd.DataFrame(itertools.combinations(teams, 2), columns=[\"TeamID1\", \"TeamID2\"])\n\nm_matchups = generate_matchups(m_teams_2025)\nw_matchups = generate_matchups(w_teams_2025)\n\n# Prepare submission dataset\ndef prepare_submission_data(matchups, team_stats, seeds):\n    df = matchups.merge(team_stats, left_on=\"TeamID1\", right_on=\"TeamID\").copy()\n    df = df.merge(team_stats, left_on=\"TeamID2\", right_on=\"TeamID\", suffixes=(\"_T1\", \"_T2\")).copy()\n\n    # Merge seed info\n    df = df.merge(seeds.rename(columns={\"TeamID\": \"TeamID1\", \"Seed\": \"Seed_T1\"}), on=\"TeamID1\", how=\"left\")\n    df = df.merge(seeds.rename(columns={\"TeamID\": \"TeamID2\", \"Seed\": \"Seed_T2\"}), on=\"TeamID2\", how=\"left\")\n\n    # Compute feature differences\n    df[\"WinRatio_Diff\"] = df[\"WinRatio_T1\"] - df[\"WinRatio_T2\"]\n    df[\"PointMargin_Diff\"] = df[\"PointMargin_T1\"] - df[\"PointMargin_T2\"]\n    df[\"AvgPointsScored_Diff\"] = df[\"AvgPointsScored_T1\"] - df[\"AvgPointsScored_T2\"]\n    df[\"AvgPointsAllowed_Diff\"] = df[\"AvgPointsAllowed_T1\"] - df[\"AvgPointsAllowed_T2\"]\n    df[\"Seed_Diff\"] = df[\"Seed_T2\"] - df[\"Seed_T1\"]\n\n    # FIX: Remove inplace warning by reassigning column\n    df[\"Seed_Diff\"] = df[\"Seed_Diff\"].fillna(0)\n\n    # Create ID column in format \"2025_TeamID1_TeamID2\"\n    df[\"ID\"] = \"2025_\" + df[\"TeamID1\"].astype(str) + \"_\" + df[\"TeamID2\"].astype(str)\n\n    return df[[\"ID\", \"WinRatio_Diff\", \"PointMargin_Diff\", \"AvgPointsScored_Diff\", \"AvgPointsAllowed_Diff\", \"Seed_Diff\"]]\n\nm_submission_data = prepare_submission_data(m_matchups, m_teams_2025, m_seeds_2025)\nw_submission_data = prepare_submission_data(w_matchups, w_teams_2025, w_seeds_2025)\n\n# Define features\nFEATURES = [\"WinRatio_Diff\", \"PointMargin_Diff\", \"AvgPointsScored_Diff\", \"AvgPointsAllowed_Diff\", \"Seed_Diff\"]\nBATCH_SIZE = 5000\nsubmission_chunks = []\n\ndef process_batches(submission_data, model, label):\n    \"\"\"Processes predictions in batches and avoids memory issues.\"\"\"\n    for i in range(0, len(submission_data), BATCH_SIZE):\n        print(f\"Processing {label} matchups {i} to {i + BATCH_SIZE}...\")\n\n        chunk = submission_data.iloc[i:i + BATCH_SIZE].copy()\n\n        # FIX: Ensure model expects feature names\n        chunk_features = chunk[FEATURES].to_numpy()\n        chunk[\"Pred\"] = model.predict_proba(chunk_features)[:, 1]\n\n        submission_chunks.append(chunk[[\"ID\", \"Pred\"]])\n\n# Process predictions for both men's and women's tournaments\nprocess_batches(m_submission_data, model_m, \"men's\")\nprocess_batches(w_submission_data, model_w, \"women's\")\n\n# Combine and save the submission\nsubmission_data = pd.concat(submission_chunks, axis=0)\nsubmission_data.to_csv(\"submission.csv\", index=False)\n\nprint(\"✅ Submission file 'submission.csv' is ready!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T07:39:52.222159Z","iopub.execute_input":"2025-02-21T07:39:52.222790Z","iopub.status.idle":"2025-02-21T07:39:53.430146Z","shell.execute_reply.started":"2025-02-21T07:39:52.222738Z","shell.execute_reply":"2025-02-21T07:39:53.428916Z"}},"outputs":[],"execution_count":null}]}